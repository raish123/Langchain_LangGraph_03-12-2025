{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086386f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\Langchain_LangGraph_03-12-2025\\MyProject\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook ka folder\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "\n",
    "# Project root = parent folder\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "# Add project root to import path\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bb197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-10 00:21:07,198]-config_variable.py-INFO -Loading the environment Variable\n",
      "[2025-12-10 00:21:07,202]-config_variable.py-INFO -Environment Variable successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "#now importing all the Module which is used to build the AI Model.\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from exception import CustomException\n",
    "from logger_config import logger\n",
    "import os,sys\n",
    "\n",
    "#using openai chat model and embedding models\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "\n",
    "#using groq chat model \n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#using open source chat model from hugging Face\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEmbeddings,HuggingFaceEndpoint\n",
    "\n",
    "from config import *\n",
    "\n",
    "from langchain_core.runnables import RunnableBranch,RunnableLambda,RunnableParallel,RunnableSequence,RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0f5c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Langchain_LangGraph_03-12-2025\\\\MyProject\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7e93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Langgraph related Modules\n",
    "import langgraph\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from dataclasses import dataclass\n",
    "from typing import TypedDict\n",
    "from typing import Literal,List,Annotated\n",
    "from langchain_core.messages import AnyMessage,AIMessage,HumanMessage,ToolMessage\n",
    "\n",
    "from pydantic import BaseModel #using this class we can perform validation to schema\n",
    "\n",
    "from langgraph.prebuilt import tool_node,tools_condition #in this class we put all tools together\n",
    "#tools_condition wrt to tool msg it will route the flow data to ttol node to perform execution\n",
    "\n",
    "from langchain_core.tools import tool,Tool,StructuredTool\n",
    "\n",
    "from langgraph.graph.message import BaseMessage #this is special class which hold every mesaage init.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5236d8a",
   "metadata": {},
   "source": [
    "## step:1) defining the models components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8971183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000028E625E38E0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000028E6284D1F0>, root_client=<openai.OpenAI object at 0x0000028E625E3610>, root_async_client=<openai.AsyncOpenAI object at 0x0000028E6277D850>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2 #we call as creative parameter\n",
    ")\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63626169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028E62F11DC0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028E62F173A0>, model_name='llama-3.1-8b-instant', temperature=0.2, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.2 #we call as creative parameter\n",
    ")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cd8c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='meta-llama/Llama-3.1-8B-Instruct', repetition_penalty=1.03, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='meta-llama/Llama-3.1-8B-Instruct', client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>, async_client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>, task='text-generation'), model_id='meta-llama/Llama-3.1-8B-Instruct', model_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(  \n",
    "repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",  \n",
    "task=\"text-generation\",  \n",
    "max_new_tokens=512,  \n",
    "do_sample=False,  \n",
    "repetition_penalty=1.03,  \n",
    ")  \n",
    "\n",
    "model3 = ChatHuggingFace(llm=llm, verbose=True)\n",
    "model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edceede",
   "metadata": {},
   "source": [
    "## building different type of complex workflows using LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130f39a",
   "metadata": {},
   "source": [
    "### 1) building Normal Agentic workflow by langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434046f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee25c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_prompt = hub.pull(\"hwchase17/react\")\n",
    "react_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f78ac",
   "metadata": {},
   "source": [
    "## now providing the tools support to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7053d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "\n",
    "def tavily_search_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web using Tavily and return summarized results.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query provided by the user.\n",
    "\n",
    "    Returns:\n",
    "        str: Search results as text.\n",
    "    \"\"\"\n",
    "    response = tavily_client.search(query=query, max_results=1)\n",
    "    \n",
    "    results = response.get(\"results\", [])\n",
    "    summaries = [\n",
    "        f\"{r['title']}: {r['content'][:120]}\"\n",
    "        for r in results\n",
    "    ]\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "\n",
    "search_tool = Tool(\n",
    "    name='search',\n",
    "    func=tavily_search_tool,\n",
    "    description=\"Search the internet for up-to-date information\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b184239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_exa import ExaSearchResults\n",
    "\n",
    "# # Initialize the ExaSearchResults tool\n",
    "# search_tool = ExaSearchResults(\n",
    "#     num_results=1,\n",
    "#     highlights=False,\n",
    "#     text_contents_options={\"max_characters\": 1000}\n",
    "# )\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be51a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class MultiplyArgs(BaseModel):\n",
    "    a: int = Field(..., description=\"First number\")\n",
    "    b: int = Field(..., description=\"Second number\")\n",
    "\n",
    "@tool(args_schema=MultiplyArgs)\n",
    "def Multiplication(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b03c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='search', description='Search the internet for up-to-date information', func=<function tavily_search_tool at 0x0000028E649328B0>),\n",
       " StructuredTool(name='Multiplication', description='Multiply two integers.', args_schema=<class '__main__.MultiplyArgs'>, func=<function Multiplication at 0x0000028E649FA5E0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining all tools together.\n",
    "lst_tools=[search_tool,Multiplication]\n",
    "lst_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ae089",
   "metadata": {},
   "source": [
    "### now creating an agents that can think and react based on user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f0ca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'search(query: str) -> str - Search the internet for up-to-date information\\nMultiplication(a: int, b: int) -> int - Multiply two integers.', 'tool_names': 'search, Multiplication'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028E62F11DC0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028E62F173A0>, model_name='llama-3.1-8b-instant', temperature=0.2, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thinkagent = create_react_agent(\n",
    "    llm=model2,\n",
    "    tools=lst_tools,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "thinkagent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda0967",
   "metadata": {},
   "source": [
    "### now using agentexecutor that will execute the agent and also validating response is based on query or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f85e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'search(query: str) -> str - Search the internet for up-to-date information\\nMultiplication(a: int, b: int) -> int - Multiply two integers.', 'tool_names': 'search, Multiplication'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000028E62F11DC0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000028E62F173A0>, model_name='llama-3.1-8b-instant', temperature=0.2, model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='search', description='Search the internet for up-to-date information', func=<function tavily_search_tool at 0x0000028E649328B0>), StructuredTool(name='Multiplication', description='Multiply two integers.', args_schema=<class '__main__.MultiplyArgs'>, func=<function Multiplication at 0x0000028E649FA5E0>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentexecutor = AgentExecutor(\n",
    "    agent=thinkagent,\n",
    "    tools=lst_tools,\n",
    "    verbose=True,\n",
    "    #max_iterations=6,          # ðŸ”¥ VERY IMPORTANT\n",
    "    #early_stopping_method=\"force\"\n",
    ")\n",
    "agentexecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b01f78",
   "metadata": {},
   "source": [
    "### now invoking agent to perform execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "751a0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "[2025-12-10 00:21:11,350]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the best route from Andheri to Borivali, I need to know the public transportation options available in Mumbai.\n",
      "Action: search\n",
      "Action Input: \"best route from Andheri to Borivali Mumbai\"\u001b[0m\u001b[36;1m\u001b[1;3mAndheri (Station) to Borivali - 5 ways to travel via train, and line 203 ...: The best way to get from Andheri (Station) to Borivali is to train which takes 24 min and costs â‚¹6 - â‚¹70. Alternatively,\u001b[0m[2025-12-10 00:21:12,593]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\n",
      "Thought: To find the best route from Andheri to Borivali, I need to know the public transportation options available in Mumbai.\n",
      "Action: search\n",
      "Action Input: \"best route from Andheri to Borivali Mumbai\"\u001b[0m\u001b[36;1m\u001b[1;3mAndheri (Station) to Borivali - 5 ways to travel via train, and line 203 ...: The best way to get from Andheri (Station) to Borivali is to train which takes 24 min and costs â‚¹6 - â‚¹70. Alternatively,\u001b[0m[2025-12-10 00:21:13,946]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\n",
      "Thought: To find the best route from Andheri to Borivali, I need to know the public transportation options available in Mumbai.\n",
      "Action: search\n",
      "Action Input: \"best route from Andheri to Borivali Mumbai\"\u001b[0m\u001b[36;1m\u001b[1;3mAndheri (Station) to Borivali - 5 ways to travel via train, and line 203 ...: The best way to get from Andheri (Station) to Borivali is to train which takes 24 min and costs â‚¹6 - â‚¹70. Alternatively,\u001b[0m[2025-12-10 00:21:15,373]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\n",
      "Thought: To find the best route from Andheri to Borivali, I need to know the public transportation options available in Mumbai.\n",
      "Action: search\n",
      "Action Input: \"best route from Andheri to Borivali Mumbai\"\u001b[0m\u001b[36;1m\u001b[1;3mAndheri (Station) to Borivali - 5 ways to travel via train, and line 203 ...: The best way to get from Andheri (Station) to Borivali is to train which takes 24 min and costs â‚¹6 - â‚¹70. Alternatively,\u001b[0m[2025-12-10 00:21:16,978]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\n",
      "Thought: To find the best route from Andheri to Borivali, I need to know the public transportation options available in Mumbai.\n",
      "Action: search\n",
      "Action Input: \"best route from Andheri to Borivali Mumbai\"\u001b[0m\u001b[36;1m\u001b[1;3mAndheri (Station) to Borivali - 5 ways to travel via train, and line 203 ...: The best way to get from Andheri (Station) to Borivali is to train which takes 24 min and costs â‚¹6 - â‚¹70. Alternatively,\u001b[0m[2025-12-10 00:21:18,394]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32;1m\u001b[1;3mIt seems like there's an infinite loop of searching for the same information. I'll stop the loop by assuming that I have found the relevant information.\n",
      "\n",
      "Thought: I now know the public transportation options available in Mumbai.\n",
      "Thought: The best way to get from Andheri to Borivali is by train, which takes 24 minutes and costs â‚¹6 - â‚¹70.\n",
      "Thought: I now know the best route from Andheri to Borivali.\n",
      "Final Answer: The best route from Andheri to Borivali is by train, which takes 24 minutes and costs â‚¹6 - â‚¹70.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).',\n",
       " 'output': 'The best route from Andheri to Borivali is by train, which takes 24 minutes and costs â‚¹6 - â‚¹70.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agentexecutor.invoke(input={'input':\n",
    "    \"Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c458767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e92f333e",
   "metadata": {},
   "source": [
    "## Now Building Agent using LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0e6ed",
   "metadata": {},
   "source": [
    "### 1) building Agentic workflow by langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd338a3b",
   "metadata": {},
   "source": [
    "#### defining state or memory schema for this workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0280e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class AgentSchema(TypedDict):\n",
    "    messages : Annotated[list[str],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1ab59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x28e64ad0970>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now defining the graph object by passing state memory into it.\n",
    "graph = StateGraph(state_schema=AgentSchema)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db723bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='search', description='Search the internet for up-to-date information', func=<function tavily_search_tool at 0x0000028E649328B0>),\n",
       " StructuredTool(name='Multiplication', description='Multiply two integers.', args_schema=<class '__main__.MultiplyArgs'>, func=<function Multiplication at 0x0000028E649FA5E0>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e099e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now adding the nodes  to graph.\n",
    "#1)llmwithtools 2)toolnode\n",
    "def LLMWithToolNode(state:AgentSchema)->AgentSchema:\n",
    "    #now fetching the latest message from state.\n",
    "    latest_msg = state['messages']\n",
    "    \n",
    "    #now wrapping the llm with tool.\n",
    "    llm_with_tool = model1.bind_tools(tools=lst_tools)\n",
    "    \n",
    "    #converting dynamic user prompt to structure instruction prompt.\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        \n",
    "        You are an intelligent AI assistant acting as a tool-augmented agent.\n",
    "\n",
    "        Your job is to:\n",
    "        1. Understand the user's latest message.\n",
    "        2. Decide whether a tool is required to answer the request.\n",
    "        3. If a tool is required, select the most relevant tool and provide accurate inputs.\n",
    "        4. If no tool is required, answer directly using your knowledge.\n",
    "        5. Never hallucinate tool results â€” only use tool outputs when they are actually executed.\n",
    "        6. Produce clear, concise, and helpful responses.\n",
    "\n",
    "        TOOLS AVAILABLE:\n",
    "        {lst_tools}\n",
    "\n",
    "        CONVERSATION HISTORY:\n",
    "        {latest_msg}\n",
    "        \n",
    "        \"\"\",input_variables=['lst_tools','latest_msg']\n",
    "        \n",
    "    )\n",
    "    \n",
    "    #forming chain to perform execution.\n",
    "    chain = prompt | llm_with_tool\n",
    "    \n",
    "    #invoking the chain for execution.\n",
    "    response= chain.invoke(input={'lst_tools':lst_tools,'latest_msg':latest_msg})\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'messages': [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3345287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'langgraph.prebuilt.tool_node' from 'c:\\\\anaconda\\\\envs\\\\tf-gpu\\\\lib\\\\site-packages\\\\langgraph\\\\prebuilt\\\\tool_node.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "toolnode = ToolNode(tools=lst_tools)\n",
    "tool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bf34f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x28e64ad0970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now adding tools and nodes to graph to build workflow.\n",
    "graph.add_node(node=\"LLMWithToolNode\",action=LLMWithToolNode)\n",
    "graph.add_node(node=\"toolnode\",action=toolnode)\n",
    "graph.add_edge(start_key=START,end_key=\"LLMWithToolNode\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    'LLMWithToolNode',\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\":\"toolnode\",\n",
    "        \"__end__\":END\n",
    "    }\n",
    "##tools_condition check wheather tool msg present from reposne coming from chat_node if yes redirect to tool_node or else will end.\n",
    ")\n",
    "graph.add_edge(start_key=\"toolnode\",end_key=\"LLMWithToolNode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "875f2d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000028E649F9C10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = graph.compile()\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3312ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-10 00:21:20,315]-_client.py-INFO -HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-12-10 00:21:21,311]-_client.py-INFO -HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 2 multiply by 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Multiplication (call_LLxYlswX1zKuVTcsw6CYkE7T)\n",
      " Call ID: call_LLxYlswX1zKuVTcsw6CYkE7T\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: Multiplication\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 by 3 is 6. This calculation was performed using the Multiplication tool. If you have any more questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "#now defining an initializing initial state.\n",
    "state = AgentSchema(messages=[HumanMessage(\"What is 2 multiply by 3\")])\n",
    "\n",
    "#now passing the state to workflow.\n",
    "result = workflow.invoke(input=state)\n",
    "\n",
    "for msg in result['messages']:\n",
    "     msg.pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc6d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-10 00:22:36,828]-_client.py-INFO -HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To summarize in one line, the best route from Andheri, Mumbai to Borivali is to take the Western Express Highway.\n"
     ]
    }
   ],
   "source": [
    "#now defining an initializing initial state.\n",
    "state = AgentSchema(messages=[HumanMessage(\"Summarize in one line the best route from Andheri, Mumbai (source) to Borivali (destination).\")])\n",
    "\n",
    "#now passing the state to workflow.\n",
    "result = workflow.invoke(input=state)\n",
    "\n",
    "for msg in result['messages']:\n",
    "     msg.pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15d782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
