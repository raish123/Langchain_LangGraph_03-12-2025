{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086386f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\Langchain_LangGraph_03-12-2025\\MyProject\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook ka folder\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "\n",
    "# Project root = parent folder\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "# Add project root to import path\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bb197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-08 16:45:54,225]-config_variable.py-INFO -Loading the environment Variable\n",
      "[2025-12-08 16:45:54,230]-config_variable.py-INFO -Environment Variable successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "#now importing all the Module which is used to build the AI Model.\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from exception import CustomException\n",
    "from logger_config import logger\n",
    "import os,sys\n",
    "\n",
    "#using openai chat model and embedding models\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "\n",
    "#using groq chat model \n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#using open source chat model from hugging Face\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEmbeddings,HuggingFaceEndpoint\n",
    "\n",
    "from config import *\n",
    "\n",
    "from langchain_core.runnables import RunnableBranch,RunnableLambda,RunnableParallel,RunnableSequence,RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0f5c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Langchain_LangGraph_03-12-2025\\\\MyProject\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7e93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Langgraph related Modules\n",
    "import langgraph\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from dataclasses import dataclass\n",
    "from typing import TypedDict\n",
    "from typing import Literal,List,Annotated\n",
    "from langchain_core.messages import AnyMessage,AIMessage,HumanMessage,ToolMessage\n",
    "\n",
    "from pydantic import BaseModel,Field #using this class we can perform validation to schema\n",
    "\n",
    "from langgraph.prebuilt import tool_node,tools_condition #in this class we put all tools together\n",
    "#tools_condition wrt to tool msg it will route the flow data to ttol node to perform execution\n",
    "\n",
    "from langchain_core.tools import tool,Tool,StructuredTool\n",
    "\n",
    "from langgraph.graph.message import BaseMessage #this is special class which hold every mesaage init.\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser,PydanticOutputParser\n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver #this will save the converstion history in ram memory\n",
    "from langchain_core.runnables import RunnableConfig   #this will help to induce the thread_id or user identification in converstion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5236d8a",
   "metadata": {},
   "source": [
    "## step:1) defining the models components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8971183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002A7848B9ED0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002A784F1DF90>, root_client=<openai.OpenAI object at 0x000002A7848BA500>, root_async_client=<openai.AsyncOpenAI object at 0x000002A7848B9E40>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2 #we call as creative parameter\n",
    ")\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63626169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002A785016FB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002A785051A50>, model_name='llama-3.1-8b-instant', temperature=0.2, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.2 #we call as creative parameter\n",
    ")\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cd8c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='meta-llama/Llama-3.1-8B-Instruct', repetition_penalty=1.03, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='meta-llama/Llama-3.1-8B-Instruct', client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>, async_client=<InferenceClient(model='meta-llama/Llama-3.1-8B-Instruct', timeout=120)>, task='text-generation'), model_id='meta-llama/Llama-3.1-8B-Instruct', model_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(  \n",
    "repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",  \n",
    "task=\"text-generation\",  \n",
    "max_new_tokens=512,  \n",
    "do_sample=False,  \n",
    "repetition_penalty=1.03,  \n",
    ")  \n",
    "\n",
    "model3 = ChatHuggingFace(llm=llm, verbose=True)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc5a5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Connection at 0x2a7860b5e40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "#now forming connection with database.\n",
    "db_connection = sqlite3.connect(database=\"raishsample.db\"\n",
    "                                ,check_same_thread=False)\n",
    "\n",
    "db_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188a2183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.checkpoint.sqlite.SqliteSaver at 0x2a7860aa1d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver #this class we used to save conversation in database\n",
    "memory = SqliteSaver(conn=db_connection)\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edceede",
   "metadata": {},
   "source": [
    "## building different type of complex workflows using LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0e6ed",
   "metadata": {},
   "source": [
    "### 1) building Persistence Database Memory workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd338a3b",
   "metadata": {},
   "source": [
    "#### defining state or memory schema for this workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffdf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ConversationalSchema(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage],add_messages] #operator.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a2dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConversationalNode(state:ConversationalSchema)->ConversationalSchema:\n",
    "    #now fetching the latest user query or human message from state.\n",
    "    user_query = state['messages']\n",
    "    \n",
    "    #now converting dynamic user query to structure instruction prompt.\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are an expert conversational AI assistant.\n",
    "\n",
    "        Your task:\n",
    "        - Understand the user's intent clearly\n",
    "        - Respond in a natural, friendly, and helpful conversational tone\n",
    "        - Give a clear, concise, and accurate answer\n",
    "        - If the query is ambiguous, politely ask for clarification\n",
    "        - Do NOT hallucinate or assume missing details\n",
    "\n",
    "        User query:\n",
    "        {user_query}\n",
    "\n",
    "        Answer:\n",
    "                \"\"\",\n",
    "                input_variables=['user_query']\n",
    "    )\n",
    "    \n",
    "    #forming sequential chain to execute the task.\n",
    "    chain = prompt | model2\n",
    "    \n",
    "    #now invoking chain to perform action.\n",
    "    result = chain.invoke(input={\"user_query\":user_query})\n",
    "    \n",
    "    \n",
    "    #now adding this AImsg or updating to msg state \n",
    "    return {\n",
    "        'messages': [result]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71809232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a7861c3580>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now building the object for stategraph class.\n",
    "graph = StateGraph(state_schema=ConversationalSchema)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b3bfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a7861c3580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now adding the nodes or edges to graph.\n",
    "graph.add_node(node=\"ConversationalNode\",action=ConversationalNode)\n",
    "graph.add_edge(start_key=START,end_key=\"ConversationalNode\")\n",
    "graph.add_edge(start_key=\"ConversationalNode\",end_key=END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5dd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 : RunnableConfig = {\"configurable\":{'thread_id':1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da549777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002A7861C3CA0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now compiling the workflow and making ready.\n",
    "workflow = graph.compile(checkpointer=memory)\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723bffe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-08 16:45:56,139]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How are You?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm doing well, thank you for asking. It's great to chat with you. Is there anything specific you'd like to talk about or any questions you have that I can help with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How are You?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It looks like we're starting a conversation. You asked how I'm doing, and I'm happy to report that I'm functioning well, thank you for asking. I'm a large language model, so I don't have feelings in the same way humans do, but I'm always ready to chat and help with any questions or topics you'd like to discuss.\n",
      "\n",
      "Is there something specific on your mind that you'd like to talk about, or is there a particular question you have that I can help with? I'm all ears (or rather, all text)!\n"
     ]
    }
   ],
   "source": [
    "#now passing the inital state to above workflow.\n",
    "human_msg = [HumanMessage(\"How are You?\")]\n",
    "\n",
    "state = ConversationalSchema(messages=human_msg)\n",
    "\n",
    "#passing these state to workflow (so invoking it).\n",
    "response = workflow.invoke(input=state,config=config1)\n",
    "\n",
    "for msg in response['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83724b",
   "metadata": {},
   "source": [
    "# iterating the workflow for conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67eebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  hello my name is raees\n",
      "[2025-12-08 16:46:07,629]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "AI:  Hello Raees, nice to meet you. It's great to hear your name. Is there something specific you'd like to talk about or ask, or would you like to chat and get to know each other better?\n",
      "Human:  can you tell me about china in one line\n",
      "[2025-12-08 16:46:24,840]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "AI:  Hello Raees, I'd be happy to help you with your question about China. Here's a one-line summary: China is the world's most populous country, with a vast territory, rich history, and a rapidly growing economy, known for its ancient civilization, stunning landscapes, and modern megacities. Is there anything else you'd like to know about China or would you like to explore other topics?\n",
      "Human:  how far china is wrt to india\n",
      "[2025-12-08 16:46:49,081]-_client.py-INFO -HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "AI:  It seems like you're asking about the geographical distance between China and India. However, to provide a more accurate answer, I'd like to clarify that the question \"how far china is wrt to india\" is a bit ambiguous. Could you please provide more context or clarify what you mean by \"how far\"? Are you asking about the distance in kilometers, the travel time, or perhaps something else?\n",
      "Human:  bye\n",
      "Bot: Bye! Have a great day ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "thread_id = \"3\"\n",
    "while(True):\n",
    "    #taking the human message.\n",
    "    user = input(\"You: \")\n",
    "    print(\"Human: \",user)\n",
    "    \n",
    "    \n",
    "    if user.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"Bot: Bye! Have a great day ðŸ˜Š\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        config2 : RunnableConfig = {\"configurable\":{'thread_id':thread_id}}\n",
    "\n",
    "        #passing these state to workflow (so invoking it).\n",
    "        response = workflow.invoke(input={'messages':[HumanMessage(content=user)]},config=config2)\n",
    "        print('Bot: ', response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f706b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ca2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7c161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c12cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f68348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831569c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d82f51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f708840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86094de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88019f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58f2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e120389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca652290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2f74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fd4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9498f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3657c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9ab4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a03cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45aca11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae30be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b07c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33d1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb856ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
